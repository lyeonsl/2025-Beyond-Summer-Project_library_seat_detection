{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "T1h60Xr0jE_8",
        "uRJmh548jKbf",
        "RivXRJDEjXkd",
        "6OqwVsQU2bWt",
        "Z81lJFLD2dCt",
        "4foRzPe63XbA"
      ],
      "authorship_tag": "ABX9TyMLCm7lLm2gmFfGNkxXjTvd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lyeonsl/2025-Beyond-Summer-Project_library_seat_detection/blob/main/2025_Beyond_Summer_Project_Pre_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5주차(비대면) - 재라벨링한 Dataset Yolov8 학습\n",
        "### 직접 수집한 도서관 이미지를 라벨링한 데이터셋으로 학습\n",
        ">"
      ],
      "metadata": {
        "id": "GNUPHupLivAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "kZr_Z7B3GYjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 런타임 다시 시작 & 캐시 초기화"
      ],
      "metadata": {
        "id": "7Ed6dLk6D96w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "O8BuNodsDJbk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. zip 파일 업로드\n",
        "\n"
      ],
      "metadata": {
        "id": "3OWQ1eF2iz7F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH66_aZTir1S"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # zip 파일 업로드"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 압축 해제 및 경로 준비"
      ],
      "metadata": {
        "id": "r5AxkfC7i-Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/Beyond.v3i.yolov8.zip\"\n",
        "extract_dir = \"/content/Beyond.v3i.yolov8\"\n",
        "\n",
        "# 압축 해제\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ],
      "metadata": {
        "id": "UYuPQtX9i7yo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. test/valid 나누기"
      ],
      "metadata": {
        "id": "2x7XlnB11HGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 기존 데이터 경로\n",
        "base_path = '/content/Beyond.v3i.yolov8'\n",
        "img_dir = os.path.join(base_path, 'train/images')\n",
        "lbl_dir = os.path.join(base_path, 'train/labels')\n",
        "\n",
        "# 출력 경로\n",
        "train_img_dir = os.path.join(base_path, 'images/train')\n",
        "val_img_dir   = os.path.join(base_path, 'images/val')\n",
        "train_lbl_dir = os.path.join(base_path, 'labels/train')\n",
        "val_lbl_dir   = os.path.join(base_path, 'labels/val')\n",
        "\n",
        "# 디렉토리 생성\n",
        "for d in [train_img_dir, val_img_dir, train_lbl_dir, val_lbl_dir]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# 이미지 파일 리스트\n",
        "img_files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# 학습/검증 분할\n",
        "train_imgs, val_imgs = train_test_split(img_files, test_size=0.2, random_state=42)\n",
        "\n",
        "def move_data(file_list, src_img_dir, src_lbl_dir, dst_img_dir, dst_lbl_dir):\n",
        "    for f in file_list:\n",
        "        img_src = os.path.join(src_img_dir, f)\n",
        "        lbl_src = os.path.join(src_lbl_dir, os.path.splitext(f)[0] + '.txt')\n",
        "\n",
        "        img_dst = os.path.join(dst_img_dir, f)\n",
        "        lbl_dst = os.path.join(dst_lbl_dir, os.path.splitext(f)[0] + '.txt')\n",
        "\n",
        "        shutil.copyfile(img_src, img_dst)\n",
        "        if os.path.exists(lbl_src):\n",
        "            shutil.copyfile(lbl_src, lbl_dst)\n",
        "\n",
        "# 이동 실행\n",
        "move_data(train_imgs, img_dir, lbl_dir, train_img_dir, train_lbl_dir)\n",
        "move_data(val_imgs, img_dir, lbl_dir, val_img_dir, val_lbl_dir)\n",
        "\n",
        "print(\"기존 이미지/라벨 → train/val 분할 완료\")"
      ],
      "metadata": {
        "id": "imMErSCp1Ce7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 디렉토리 경로 설정\n",
        "base_dir = '/content/Beyond.v3i.yolov8/images'\n",
        "subdirs = ['train', 'val']\n",
        "\n",
        "# 이미지 확장자 정의 (YOLO에서 주로 사용되는 포맷들)\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "\n",
        "# 각 폴더에 있는 이미지 개수 출력\n",
        "for subdir in subdirs:\n",
        "    folder_path = os.path.join(base_dir, subdir)\n",
        "    image_count = len([\n",
        "        f for f in os.listdir(folder_path)\n",
        "        if os.path.splitext(f)[1].lower() in image_extensions\n",
        "    ])\n",
        "    print(f\"{subdir} 이미지 개수: {image_count}장\")"
      ],
      "metadata": {
        "id": "iVEH3BAJ0Xp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 데이터 증강 및 데이터 합치기"
      ],
      "metadata": {
        "id": "IjEUcSTI1jSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import albumentations as A\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 디렉토리 설정\n",
        "input_img_dir = '/content/Beyond.v3i.yolov8/images/train'\n",
        "input_lbl_dir = '/content/Beyond.v3i.yolov8/labels/train'\n",
        "\n",
        "output_img_dir = '/content/augmented/images'\n",
        "output_lbl_dir = '/content/augmented/labels'\n",
        "os.makedirs(output_img_dir, exist_ok=True)\n",
        "os.makedirs(output_lbl_dir, exist_ok=True)\n",
        "\n",
        "# 클래스 수 (YOLO format assumes class indices)\n",
        "class_names = ['empty', 'occupied']\n",
        "\n",
        "# 증강 파이프라인 (bbox 처리 포함)\n",
        "augment = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.3),\n",
        "    A.Rotate(limit=15, p=0.3),\n",
        "    A.GaussNoise(p=0.2),\n",
        "    A.Resize(416, 416, p=1.0),  # YOLO 학습용 고정 크기\n",
        "],\n",
        "bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'], min_visibility=0.3))\n",
        "\n",
        "# 증강 횟수\n",
        "AUG_PER_IMAGE = 2\n",
        "\n",
        "image_files = [f for f in os.listdir(input_img_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "for img_file in tqdm(image_files):\n",
        "    img_path = os.path.join(input_img_dir, img_file)\n",
        "    label_path = os.path.join(input_lbl_dir, os.path.splitext(img_file)[0] + '.txt')\n",
        "\n",
        "    # 이미지 로드\n",
        "    image = cv2.imread(img_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    h, w = image.shape[:2]\n",
        "\n",
        "    # 라벨 로드\n",
        "    bboxes = []\n",
        "    class_labels = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                cls, x, y, bw, bh = map(float, line.strip().split())\n",
        "                bboxes.append([x, y, bw, bh])\n",
        "                class_labels.append(int(cls))\n",
        "    else:\n",
        "        continue  # 라벨 없으면 스킵\n",
        "\n",
        "    # 증강 반복\n",
        "    for i in range(AUG_PER_IMAGE):\n",
        "        augmented = augment(image=image, bboxes=bboxes, class_labels=class_labels)\n",
        "        aug_img = augmented['image']\n",
        "        aug_bboxes = augmented['bboxes']\n",
        "        aug_labels = augmented['class_labels']\n",
        "\n",
        "        # 파일명 설정\n",
        "        base_name = os.path.splitext(img_file)[0]\n",
        "        aug_img_name = f\"{base_name}_aug{i}.jpg\"\n",
        "        aug_lbl_name = f\"{base_name}_aug{i}.txt\"\n",
        "\n",
        "        # 이미지 저장\n",
        "        aug_img_bgr = cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR)\n",
        "        cv2.imwrite(os.path.join(output_img_dir, aug_img_name), aug_img_bgr)\n",
        "\n",
        "        # 라벨 저장\n",
        "        with open(os.path.join(output_lbl_dir, aug_lbl_name), 'w') as f:\n",
        "            for label, box in zip(aug_labels, aug_bboxes):\n",
        "                f.write(f\"{label} {box[0]:.6f} {box[1]:.6f} {box[2]:.6f} {box[3]:.6f}\\n\")"
      ],
      "metadata": {
        "id": "LwqmruOH0eSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 증강된 이미지 및 라벨 경로\n",
        "aug_img_dir = '/content/augmented/images'\n",
        "aug_lbl_dir = '/content/augmented/labels'\n",
        "\n",
        "# 클래스 이름 정의 (YOLO 라벨 인덱스 기준)\n",
        "class_names = ['empty', 'occupied']\n",
        "\n",
        "# 시각화할 이미지 수\n",
        "NUM_SAMPLES = 5\n",
        "\n",
        "# 이미지 파일 리스트\n",
        "image_files = [f for f in os.listdir(aug_img_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# 무작위 샘플 선택\n",
        "for img_file in random.sample(image_files, min(NUM_SAMPLES, len(image_files))):\n",
        "    img_path = os.path.join(aug_img_dir, img_file)\n",
        "    label_path = os.path.join(aug_lbl_dir, os.path.splitext(img_file)[0] + '.txt')\n",
        "\n",
        "    image = cv2.imread(img_path)\n",
        "    h, w = image.shape[:2]\n",
        "\n",
        "    if not os.path.exists(label_path):\n",
        "        print(f\"라벨 없음: {label_path}\")\n",
        "        continue\n",
        "\n",
        "    # 라벨 읽기 및 바운딩박스 시각화\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            cls, x, y, bw, bh = map(float, line.strip().split())\n",
        "            x1 = int((x - bw / 2) * w)\n",
        "            y1 = int((y - bh / 2) * h)\n",
        "            x2 = int((x + bw / 2) * w)\n",
        "            y2 = int((y + bh / 2) * h)\n",
        "            color = (0, 255, 0) if int(cls) == 0 else (0, 0, 255)\n",
        "            label = class_names[int(cls)]\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "    print(f\"시각화: {img_file}\")\n",
        "    cv2_imshow(image)"
      ],
      "metadata": {
        "id": "ghrEeYnG0iUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 소스 디렉토리 목록\n",
        "image_sources = [\n",
        "    '/content/Beyond.v3i.yolov8/images/train',\n",
        "    '/content/augmented/images'\n",
        "]\n",
        "\n",
        "label_sources = [\n",
        "    '/content/Beyond.v3i.yolov8/labels/train',\n",
        "    '/content/augmented/labels'\n",
        "]\n",
        "\n",
        "# 대상 디렉토리\n",
        "merged_image_dir = '/content/merged/images'\n",
        "merged_label_dir = '/content/merged/labels'\n",
        "\n",
        "# 확장자 설정\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "label_extension = '.txt'\n",
        "\n",
        "# 대상 디렉토리 생성\n",
        "os.makedirs(merged_image_dir, exist_ok=True)\n",
        "os.makedirs(merged_label_dir, exist_ok=True)\n",
        "\n",
        "# 이미지 + 라벨 병합\n",
        "for img_src, lbl_src in zip(image_sources, label_sources):\n",
        "    for filename in os.listdir(img_src):\n",
        "        if os.path.splitext(filename)[1].lower() in image_extensions:\n",
        "            base_name, ext = os.path.splitext(filename)\n",
        "\n",
        "            src_img_path = os.path.join(img_src, filename)\n",
        "            src_lbl_path = os.path.join(lbl_src, f\"{base_name}{label_extension}\")\n",
        "\n",
        "            dst_img_path = os.path.join(merged_image_dir, filename)\n",
        "            dst_lbl_path = os.path.join(merged_label_dir, f\"{base_name}{label_extension}\")\n",
        "\n",
        "            # 이름 중복 방지\n",
        "            counter = 1\n",
        "            while os.path.exists(dst_img_path) or os.path.exists(dst_lbl_path):\n",
        "                new_base = f\"{base_name}_{counter}\"\n",
        "                dst_img_path = os.path.join(merged_image_dir, f\"{new_base}{ext}\")\n",
        "                dst_lbl_path = os.path.join(merged_label_dir, f\"{new_base}{label_extension}\")\n",
        "                counter += 1\n",
        "\n",
        "            shutil.copy2(src_img_path, dst_img_path)\n",
        "\n",
        "            if os.path.exists(src_lbl_path):\n",
        "                shutil.copy2(src_lbl_path, dst_lbl_path)\n",
        "\n",
        "print(\"모든 이미지와 라벨이 /content/merged 디렉토리로 병합 완료됨\")"
      ],
      "metadata": {
        "id": "rcHL5rHS0lYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 경로 설정\n",
        "image_dir = '/content/merged/images'\n",
        "label_dir = '/content/merged/labels'\n",
        "\n",
        "# 확장자 설정\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "label_extension = '.txt'\n",
        "\n",
        "# 이미지 개수 세기\n",
        "image_count = len([\n",
        "    f for f in os.listdir(image_dir)\n",
        "    if os.path.splitext(f)[1].lower() in image_extensions\n",
        "])\n",
        "\n",
        "# 라벨 개수 세기\n",
        "label_count = len([\n",
        "    f for f in os.listdir(label_dir)\n",
        "    if f.endswith(label_extension)\n",
        "])\n",
        "\n",
        "print(f\"이미지 수: {image_count}장\")\n",
        "print(f\"라벨 수: {label_count}개\")"
      ],
      "metadata": {
        "id": "nCvGG0GQ0m1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "class_names = ['empty', 'occupied']\n",
        "\n",
        "data = {\n",
        "    'train': '/content/merged/images',\n",
        "    'val': '/content/Beyond.v3i.yolov8/images/val',\n",
        "    'test': '/content/Beyond.v3i.yolov8/images/val',\n",
        "    'names': {i: name for i, name in enumerate(class_names)},\n",
        "    'nc': len(class_names)\n",
        "}\n",
        "\n",
        "yaml_path = '/content/merged/dataset.yaml'\n",
        "\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(data, f, default_flow_style=False)\n",
        "\n",
        "print(f\"dataset.yaml 파일 생성 완료: {yaml_path}\")\n"
      ],
      "metadata": {
        "id": "05aa2cc70o2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. YOLOv8 설치 및 모델 로드"
      ],
      "metadata": {
        "id": "AQu8XpHbjA8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ultralytics 설치\n",
        "!pip install ultralytics\n",
        "\n",
        "# 모델 로드\n",
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov8n.pt\")  # 경량 모델 (또는 yolov8s.pt 등 가능)\n"
      ],
      "metadata": {
        "id": "f_vXk2l2jDak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 구글 코랩 테스트용"
      ],
      "metadata": {
        "id": "YG6TVka2GF-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 시작\n",
        "model.train(\n",
        "    data=yaml_path,        # data.yaml 경로\n",
        "    epochs=10,\n",
        "    imgsz=416,\n",
        "    batch=1,\n",
        "    amp=True,\n",
        "    cache=False,\n",
        "    name=\"yolov8_chair\"\n",
        ")"
      ],
      "metadata": {
        "id": "HbCf0tIbFPlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# 이미지 폴더 경로\n",
        "image_folder = \"/content/Beyond.v31.yolov8/merged/images\"\n",
        "\n",
        "# 이미지 확장자 확인\n",
        "image_files = glob.glob(image_folder + \"/*.jpg\") + glob.glob(image_folder + \"/*.png\")\n",
        "\n",
        "print(f\"총 {len(image_files)}개의 이미지 파일이 있습니다.\")\n",
        "for f in image_files[:10]:  # 처음 10개만 출력\n",
        "    print(f)"
      ],
      "metadata": {
        "id": "1KZjH0kHFd8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. 모델 불러오기\n",
        "model = YOLO('/content/runs/detect/yolov8_chair/weights/best.pt')  # 경로 확인 필요\n",
        "\n",
        "# 2. 이미지 불러오기\n",
        "image_path = ''\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# 3. 예측 실행\n",
        "results = model(image, conf=0.1)  # conf 낮춰보기\n",
        "\n",
        "# 4. 결과 이미지 시각화\n",
        "res_plotted = results[0].plot()  # 바운딩 박스가 그려진 이미지 (numpy 배열)\n",
        "\n",
        "# 5. 이미지 출력\n",
        "plt.imshow(res_plotted)\n",
        "plt.axis('off')\n",
        "plt.title(\"YOLOv8 Chair Detection Result\")\n",
        "plt.show()\n",
        "\n",
        "# 6. 결과 출력 (박스가 실제로 있는지 확인)\n",
        "print(\"탐지된 박스 수:\", len(results[0].boxes))\n",
        "print(\"박스 정보:\", results[0].boxes.xyxy)\n",
        "print(\"클래스 정보:\", results[0].boxes.cls)\n",
        "print(\"신뢰도:\", results[0].boxes.conf)"
      ],
      "metadata": {
        "id": "DWt0r1YCFhO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측된 바운딩 박스 정보 출력\n",
        "for box in results[0].boxes:\n",
        "    cls = int(box.cls[0])\n",
        "    conf = float(box.conf[0])\n",
        "    xyxy = box.xyxy[0].tolist()\n",
        "    print(f\"Class: {model.names[cls]}, Conf: {conf:.2f}, BBox: {xyxy}\")"
      ],
      "metadata": {
        "id": "KsXssaY2Fdrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# 경로: YOLO 학습 결과 디렉토리\n",
        "results_csv_path = \"/content/runs/detect/train2/results.csv\"\n",
        "\n",
        "# CSV 불러오기\n",
        "assert os.path.exists(results_csv_path), f\"CSV 파일 없음: {results_csv_path}\"\n",
        "df = pd.read_csv(results_csv_path)\n",
        "\n",
        "# 기본 정보\n",
        "epochs = df.index + 1  # 0부터 시작하므로 +1\n",
        "\n",
        "# ✅ 그래프 그리기\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# ---- Accuracy / Precision / Recall ----\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, df[\"metrics/precision(B)\"], label=\"Precision\", marker='o')\n",
        "plt.plot(epochs, df[\"metrics/recall(B)\"], label=\"Recall\", marker='o')\n",
        "plt.plot(epochs, df[\"metrics/mAP50(B)\"], label=\"mAP50\", marker='o')\n",
        "plt.title(\"Precision / Recall / mAP\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# ---- Loss ----\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, df[\"train/box_loss\"], label=\"Box Loss\", marker='x')\n",
        "plt.plot(epochs, df[\"train/cls_loss\"], label=\"Class Loss\", marker='x')\n",
        "plt.plot(epochs, df[\"val/box_loss\"], label=\"Val Box Loss\", linestyle=\"--\")\n",
        "plt.plot(epochs, df[\"val/cls_loss\"], label=\"Val Class Loss\", linestyle=\"--\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Mx0WpFyFj_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검출 실행 (validation 이미지 대상)\n",
        "val_images_path = '/content/Beyond.v3i.yolov8/images/val'\n",
        "\n",
        "results = model.predict(\n",
        "    source=val_images_path,\n",
        "    conf=0.3,\n",
        "    save=True\n",
        ")\n",
        "\n",
        "# 시각화 결과 보기\n",
        "results[0].show()"
      ],
      "metadata": {
        "id": "0AKkuVm1FoEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# YOLO val 결과 이미지 경로\n",
        "val_result_dir = \"/content/runs/detect/val\"\n",
        "\n",
        "# 파일 리스트 불러오기\n",
        "img_files = [f for f in os.listdir(val_result_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# 무작위 5장 선택\n",
        "sample_imgs = random.sample(img_files, min(5, len(img_files)))\n",
        "\n",
        "# 시각화\n",
        "for f in sample_imgs:\n",
        "    img_path = os.path.join(val_result_dir, f)\n",
        "    img = cv2.imread(img_path)\n",
        "    print(f\"{f}\")\n",
        "    cv2_imshow(img)"
      ],
      "metadata": {
        "id": "dXCdSEyUFrhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 학습 실행 (960x960)"
      ],
      "metadata": {
        "id": "T1h60Xr0jE_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 시작\n",
        "model.train(\n",
        "    data=yaml_path,        # data.yaml 경로\n",
        "    epochs=50,\n",
        "    imgsz=960,\n",
        "    batch=4,\n",
        "    name=\"yolov8_chair\"\n",
        ")"
      ],
      "metadata": {
        "id": "GYop-AuJjH2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val()\n",
        "\n",
        "# 주요 지표 출력\n",
        "print(f\"mAP@0.5:       {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95:   {metrics.box.map:.4f}\")\n",
        "print(f\"Precision:      {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall:         {metrics.box.mr:.4f}\")"
      ],
      "metadata": {
        "id": "C55WMyXnHmKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. 학습된 모델로 예측 확인 (960x960)"
      ],
      "metadata": {
        "id": "uRJmh548jKbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# 이미지 폴더 경로\n",
        "image_folder = \"/content/Beyond.v31.yolov8/merged/images\"\n",
        "\n",
        "# 이미지 확장자 확인\n",
        "image_files = glob.glob(image_folder + \"/*.jpg\") + glob.glob(image_folder + \"/*.png\")\n",
        "\n",
        "print(f\"총 {len(image_files)}개의 이미지 파일이 있습니다.\")\n",
        "for f in image_files[:10]:  # 처음 10개만 출력\n",
        "    print(f)"
      ],
      "metadata": {
        "id": "meWwzf7YjMfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. 모델 불러오기\n",
        "model = YOLO('/content/runs/detect/yolov8_chair/weights/best.pt')  # 경로 확인 필요\n",
        "\n",
        "# 2. 이미지 불러오기\n",
        "image_path = ''\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# 3. 예측 실행\n",
        "results = model(image, conf=0.1)  # conf 낮춰보기\n",
        "\n",
        "# 4. 결과 이미지 시각화\n",
        "res_plotted = results[0].plot()  # 바운딩 박스가 그려진 이미지 (numpy 배열)\n",
        "\n",
        "# 5. 이미지 출력\n",
        "plt.imshow(res_plotted)\n",
        "plt.axis('off')\n",
        "plt.title(\"YOLOv8 Chair Detection Result\")\n",
        "plt.show()\n",
        "\n",
        "# 6. 결과 출력 (박스가 실제로 있는지 확인)\n",
        "print(\"탐지된 박스 수:\", len(results[0].boxes))\n",
        "print(\"박스 정보:\", results[0].boxes.xyxy)\n",
        "print(\"클래스 정보:\", results[0].boxes.cls)\n",
        "print(\"신뢰도:\", results[0].boxes.conf)"
      ],
      "metadata": {
        "id": "S1727UjP0k9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.names)"
      ],
      "metadata": {
        "id": "VBjkIzwmjS0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측된 바운딩 박스 정보 출력\n",
        "for box in results[0].boxes:\n",
        "    cls = int(box.cls[0])\n",
        "    conf = float(box.conf[0])\n",
        "    xyxy = box.xyxy[0].tolist()\n",
        "    print(f\"Class: {model.names[cls]}, Conf: {conf:.2f}, BBox: {xyxy}\")"
      ],
      "metadata": {
        "id": "7SblHy8bjVWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# 경로: YOLO 학습 결과 디렉토리\n",
        "results_csv_path = \"/content/runs/detect/train2/results.csv\"\n",
        "\n",
        "# CSV 불러오기\n",
        "assert os.path.exists(results_csv_path), f\"CSV 파일 없음: {results_csv_path}\"\n",
        "df = pd.read_csv(results_csv_path)\n",
        "\n",
        "# 기본 정보\n",
        "epochs = df.index + 1  # 0부터 시작하므로 +1\n",
        "\n",
        "# ✅ 그래프 그리기\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# ---- Accuracy / Precision / Recall ----\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, df[\"metrics/precision(B)\"], label=\"Precision\", marker='o')\n",
        "plt.plot(epochs, df[\"metrics/recall(B)\"], label=\"Recall\", marker='o')\n",
        "plt.plot(epochs, df[\"metrics/mAP50(B)\"], label=\"mAP50\", marker='o')\n",
        "plt.title(\"Precision / Recall / mAP\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# ---- Loss ----\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, df[\"train/box_loss\"], label=\"Box Loss\", marker='x')\n",
        "plt.plot(epochs, df[\"train/cls_loss\"], label=\"Class Loss\", marker='x')\n",
        "plt.plot(epochs, df[\"val/box_loss\"], label=\"Val Box Loss\", linestyle=\"--\")\n",
        "plt.plot(epochs, df[\"val/cls_loss\"], label=\"Val Class Loss\", linestyle=\"--\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zHrpbNqj7SmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Valid 세트 테스트 (960x960)"
      ],
      "metadata": {
        "id": "RivXRJDEjXkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 검출 실행 (validation 이미지 대상)\n",
        "val_images_path = '/content/Beyond.v3i.yolov8/images/val'\n",
        "\n",
        "results = model.predict(\n",
        "    source=val_images_path,\n",
        "    conf=0.3,\n",
        "    save=True\n",
        ")\n",
        "\n",
        "# 시각화 결과 보기\n",
        "results[0].show()\n"
      ],
      "metadata": {
        "id": "0fuHuXmKjXTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# YOLO val 결과 이미지 경로\n",
        "val_result_dir = \"/content/runs/detect/val\"\n",
        "\n",
        "# 파일 리스트 불러오기\n",
        "img_files = [f for f in os.listdir(val_result_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# 무작위 5장 선택\n",
        "sample_imgs = random.sample(img_files, min(5, len(img_files)))\n",
        "\n",
        "# 시각화\n",
        "for f in sample_imgs:\n",
        "    img_path = os.path.join(val_result_dir, f)\n",
        "    img = cv2.imread(img_path)\n",
        "    print(f\"{f}\")\n",
        "    cv2_imshow(img)"
      ],
      "metadata": {
        "id": "6CQfTPKa7h8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. 학습 실행 (640x640)"
      ],
      "metadata": {
        "id": "6OqwVsQU2bWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 시작\n",
        "model.train(\n",
        "    data=yaml_path,        # data.yaml 경로\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=1,\n",
        "    amp=True,\n",
        "    name=\"yolov8_chair\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEtTtzM-2ac8",
        "outputId": "880ba045-febe-4692-b8c0-c8f4921db46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.172 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=False, augment=False, auto_augment=randaugment, batch=1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/merged/dataset.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8_chair, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/yolov8_chair, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100%|██████████| 755k/755k [00:00<00:00, 23.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 46.3±24.6 MB/s, size: 97.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/merged/labels... 558 images, 0 backgrounds, 0 corrupt: 100%|██████████| 558/558 [00:01<00:00, 355.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/merged/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 47.1±8.0 MB/s, size: 136.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Beyond.v3i.yolov8/labels/val... 47 images, 0 backgrounds, 0 corrupt: 100%|██████████| 47/47 [00:00<00:00, 140.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Beyond.v3i.yolov8/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/yolov8_chair/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/yolov8_chair\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/558 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val()\n",
        "\n",
        "# 주요 지표 출력\n",
        "print(f\"mAP@0.5:       {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95:   {metrics.box.map:.4f}\")\n",
        "print(f\"Precision:      {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall:         {metrics.box.mr:.4f}\")"
      ],
      "metadata": {
        "id": "Zv8-iDD72iUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. 학습된 모델로 예측 확인 (640x640)"
      ],
      "metadata": {
        "id": "Z81lJFLD2dCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# 이미지 폴더 경로\n",
        "image_folder = \"/content/Beyond.v31.yolov8/merged/images\"\n",
        "\n",
        "# 이미지 확장자 확인\n",
        "image_files = glob.glob(image_folder + \"/*.jpg\") + glob.glob(image_folder + \"/*.png\")\n",
        "\n",
        "print(f\"총 {len(image_files)}개의 이미지 파일이 있습니다.\")\n",
        "for f in image_files[:10]:  # 처음 10개만 출력\n",
        "    print(f)"
      ],
      "metadata": {
        "id": "JI43Xne72nY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. 모델 불러오기\n",
        "model = YOLO('/content/runs/detect/yolov8_chair/weights/best.pt')  # 경로 확인 필요\n",
        "\n",
        "# 2. 이미지 불러오기\n",
        "image_path = ''\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# 3. 예측 실행\n",
        "results = model(image, conf=0.1)  # conf 낮춰보기\n",
        "\n",
        "# 4. 결과 이미지 시각화\n",
        "res_plotted = results[0].plot()  # 바운딩 박스가 그려진 이미지 (numpy 배열)\n",
        "\n",
        "# 5. 이미지 출력\n",
        "plt.imshow(res_plotted)\n",
        "plt.axis('off')\n",
        "plt.title(\"YOLOv8 Chair Detection Result\")\n",
        "plt.show()\n",
        "\n",
        "# 6. 결과 출력 (박스가 실제로 있는지 확인)\n",
        "print(\"탐지된 박스 수:\", len(results[0].boxes))\n",
        "print(\"박스 정보:\", results[0].boxes.xyxy)\n",
        "print(\"클래스 정보:\", results[0].boxes.cls)\n",
        "print(\"신뢰도:\", results[0].boxes.conf)"
      ],
      "metadata": {
        "id": "N_NM76X6221H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측된 바운딩 박스 정보 출력\n",
        "for box in results[0].boxes:\n",
        "    cls = int(box.cls[0])\n",
        "    conf = float(box.conf[0])\n",
        "    xyxy = box.xyxy[0].tolist()\n",
        "    print(f\"Class: {model.names[cls]}, Conf: {conf:.2f}, BBox: {xyxy}\")"
      ],
      "metadata": {
        "id": "tWv8t-sG3GtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# 경로: YOLO 학습 결과 디렉토리\n",
        "results_csv_path = \"/content/runs/detect/train2/results.csv\"\n",
        "\n",
        "# CSV 불러오기\n",
        "assert os.path.exists(results_csv_path), f\"CSV 파일 없음: {results_csv_path}\"\n",
        "df = pd.read_csv(results_csv_path)\n",
        "\n",
        "# 기본 정보\n",
        "epochs = df.index + 1  # 0부터 시작하므로 +1\n",
        "\n",
        "# ✅ 그래프 그리기\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# ---- Accuracy / Precision / Recall ----\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, df[\"metrics/precision(B)\"], label=\"Precision\", marker='o')\n",
        "plt.plot(epochs, df[\"metrics/recall(B)\"], label=\"Recall\", marker='o')\n",
        "plt.plot(epochs, df[\"metrics/mAP50(B)\"], label=\"mAP50\", marker='o')\n",
        "plt.title(\"Precision / Recall / mAP\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# ---- Loss ----\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, df[\"train/box_loss\"], label=\"Box Loss\", marker='x')\n",
        "plt.plot(epochs, df[\"train/cls_loss\"], label=\"Class Loss\", marker='x')\n",
        "plt.plot(epochs, df[\"val/box_loss\"], label=\"Val Box Loss\", linestyle=\"--\")\n",
        "plt.plot(epochs, df[\"val/cls_loss\"], label=\"Val Class Loss\", linestyle=\"--\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cwcKY3k07MPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Valid 세트 테스트 (640x640)"
      ],
      "metadata": {
        "id": "4foRzPe63XbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 검출 실행 (validation 이미지 대상)\n",
        "val_images_path = '/content/Beyond.v3i.yolov8/images/val'\n",
        "\n",
        "results = model.predict(\n",
        "    source=val_images_path,\n",
        "    conf=0.3,\n",
        "    save=True\n",
        ")\n",
        "\n",
        "# 시각화 결과 보기\n",
        "results[0].show()"
      ],
      "metadata": {
        "id": "HOk0lwEM3eZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# YOLO val 결과 이미지 경로\n",
        "val_result_dir = \"/content/runs/detect/val\"\n",
        "\n",
        "# 파일 리스트 불러오기\n",
        "img_files = [f for f in os.listdir(val_result_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# 무작위 5장 선택\n",
        "sample_imgs = random.sample(img_files, min(5, len(img_files)))\n",
        "\n",
        "# 시각화\n",
        "for f in sample_imgs:\n",
        "    img_path = os.path.join(val_result_dir, f)\n",
        "    img = cv2.imread(img_path)\n",
        "    print(f\"{f}\")\n",
        "    cv2_imshow(img)"
      ],
      "metadata": {
        "id": "CXnnVMK67e2W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}