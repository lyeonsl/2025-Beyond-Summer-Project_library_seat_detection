{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "T1h60Xr0jE_8",
        "uRJmh548jKbf",
        "RivXRJDEjXkd",
        "6OqwVsQU2bWt",
        "Z81lJFLD2dCt",
        "4foRzPe63XbA"
      ],
      "authorship_tag": "ABX9TyMLCm7lLm2gmFfGNkxXjTvd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lyeonsl/2025-Beyond-Summer-Project_library_seat_detection/blob/main/2025_Beyond_Summer_Project_Pre_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5ì£¼ì°¨(ë¹„ëŒ€ë©´) - ì¬ë¼ë²¨ë§í•œ Dataset Yolov8 í•™ìŠµ\n",
        "### ì§ì ‘ ìˆ˜ì§‘í•œ ë„ì„œê´€ ì´ë¯¸ì§€ë¥¼ ë¼ë²¨ë§í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµ\n",
        ">"
      ],
      "metadata": {
        "id": "GNUPHupLivAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "kZr_Z7B3GYjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ëŸ°íƒ€ì„ ë‹¤ì‹œ ì‹œì‘ & ìºì‹œ ì´ˆê¸°í™”"
      ],
      "metadata": {
        "id": "7Ed6dLk6D96w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "O8BuNodsDJbk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. zip íŒŒì¼ ì—…ë¡œë“œ\n",
        "\n"
      ],
      "metadata": {
        "id": "3OWQ1eF2iz7F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH66_aZTir1S"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # zip íŒŒì¼ ì—…ë¡œë“œ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. ì••ì¶• í•´ì œ ë° ê²½ë¡œ ì¤€ë¹„"
      ],
      "metadata": {
        "id": "r5AxkfC7i-Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/Beyond.v3i.yolov8.zip\"\n",
        "extract_dir = \"/content/Beyond.v3i.yolov8\"\n",
        "\n",
        "# ì••ì¶• í•´ì œ\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ],
      "metadata": {
        "id": "UYuPQtX9i7yo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. test/valid ë‚˜ëˆ„ê¸°"
      ],
      "metadata": {
        "id": "2x7XlnB11HGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ê¸°ì¡´ ë°ì´í„° ê²½ë¡œ\n",
        "base_path = '/content/Beyond.v3i.yolov8'\n",
        "img_dir = os.path.join(base_path, 'train/images')\n",
        "lbl_dir = os.path.join(base_path, 'train/labels')\n",
        "\n",
        "# ì¶œë ¥ ê²½ë¡œ\n",
        "train_img_dir = os.path.join(base_path, 'images/train')\n",
        "val_img_dir   = os.path.join(base_path, 'images/val')\n",
        "train_lbl_dir = os.path.join(base_path, 'labels/train')\n",
        "val_lbl_dir   = os.path.join(base_path, 'labels/val')\n",
        "\n",
        "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "for d in [train_img_dir, val_img_dir, train_lbl_dir, val_lbl_dir]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸\n",
        "img_files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# í•™ìŠµ/ê²€ì¦ ë¶„í• \n",
        "train_imgs, val_imgs = train_test_split(img_files, test_size=0.2, random_state=42)\n",
        "\n",
        "def move_data(file_list, src_img_dir, src_lbl_dir, dst_img_dir, dst_lbl_dir):\n",
        "    for f in file_list:\n",
        "        img_src = os.path.join(src_img_dir, f)\n",
        "        lbl_src = os.path.join(src_lbl_dir, os.path.splitext(f)[0] + '.txt')\n",
        "\n",
        "        img_dst = os.path.join(dst_img_dir, f)\n",
        "        lbl_dst = os.path.join(dst_lbl_dir, os.path.splitext(f)[0] + '.txt')\n",
        "\n",
        "        shutil.copyfile(img_src, img_dst)\n",
        "        if os.path.exists(lbl_src):\n",
        "            shutil.copyfile(lbl_src, lbl_dst)\n",
        "\n",
        "# ì´ë™ ì‹¤í–‰\n",
        "move_data(train_imgs, img_dir, lbl_dir, train_img_dir, train_lbl_dir)\n",
        "move_data(val_imgs, img_dir, lbl_dir, val_img_dir, val_lbl_dir)\n",
        "\n",
        "print(\"ê¸°ì¡´ ì´ë¯¸ì§€/ë¼ë²¨ â†’ train/val ë¶„í•  ì™„ë£Œ\")"
      ],
      "metadata": {
        "id": "imMErSCp1Ce7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •\n",
        "base_dir = '/content/Beyond.v3i.yolov8/images'\n",
        "subdirs = ['train', 'val']\n",
        "\n",
        "# ì´ë¯¸ì§€ í™•ì¥ì ì •ì˜ (YOLOì—ì„œ ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” í¬ë§·ë“¤)\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "\n",
        "# ê° í´ë”ì— ìˆëŠ” ì´ë¯¸ì§€ ê°œìˆ˜ ì¶œë ¥\n",
        "for subdir in subdirs:\n",
        "    folder_path = os.path.join(base_dir, subdir)\n",
        "    image_count = len([\n",
        "        f for f in os.listdir(folder_path)\n",
        "        if os.path.splitext(f)[1].lower() in image_extensions\n",
        "    ])\n",
        "    print(f\"{subdir} ì´ë¯¸ì§€ ê°œìˆ˜: {image_count}ì¥\")"
      ],
      "metadata": {
        "id": "iVEH3BAJ0Xp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. ë°ì´í„° ì¦ê°• ë° ë°ì´í„° í•©ì¹˜ê¸°"
      ],
      "metadata": {
        "id": "IjEUcSTI1jSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import albumentations as A\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ë””ë ‰í† ë¦¬ ì„¤ì •\n",
        "input_img_dir = '/content/Beyond.v3i.yolov8/images/train'\n",
        "input_lbl_dir = '/content/Beyond.v3i.yolov8/labels/train'\n",
        "\n",
        "output_img_dir = '/content/augmented/images'\n",
        "output_lbl_dir = '/content/augmented/labels'\n",
        "os.makedirs(output_img_dir, exist_ok=True)\n",
        "os.makedirs(output_lbl_dir, exist_ok=True)\n",
        "\n",
        "# í´ë˜ìŠ¤ ìˆ˜ (YOLO format assumes class indices)\n",
        "class_names = ['empty', 'occupied']\n",
        "\n",
        "# ì¦ê°• íŒŒì´í”„ë¼ì¸ (bbox ì²˜ë¦¬ í¬í•¨)\n",
        "augment = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.3),\n",
        "    A.Rotate(limit=15, p=0.3),\n",
        "    A.GaussNoise(p=0.2),\n",
        "    A.Resize(416, 416, p=1.0),  # YOLO í•™ìŠµìš© ê³ ì • í¬ê¸°\n",
        "],\n",
        "bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'], min_visibility=0.3))\n",
        "\n",
        "# ì¦ê°• íšŸìˆ˜\n",
        "AUG_PER_IMAGE = 2\n",
        "\n",
        "image_files = [f for f in os.listdir(input_img_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "for img_file in tqdm(image_files):\n",
        "    img_path = os.path.join(input_img_dir, img_file)\n",
        "    label_path = os.path.join(input_lbl_dir, os.path.splitext(img_file)[0] + '.txt')\n",
        "\n",
        "    # ì´ë¯¸ì§€ ë¡œë“œ\n",
        "    image = cv2.imread(img_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    h, w = image.shape[:2]\n",
        "\n",
        "    # ë¼ë²¨ ë¡œë“œ\n",
        "    bboxes = []\n",
        "    class_labels = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                cls, x, y, bw, bh = map(float, line.strip().split())\n",
        "                bboxes.append([x, y, bw, bh])\n",
        "                class_labels.append(int(cls))\n",
        "    else:\n",
        "        continue  # ë¼ë²¨ ì—†ìœ¼ë©´ ìŠ¤í‚µ\n",
        "\n",
        "    # ì¦ê°• ë°˜ë³µ\n",
        "    for i in range(AUG_PER_IMAGE):\n",
        "        augmented = augment(image=image, bboxes=bboxes, class_labels=class_labels)\n",
        "        aug_img = augmented['image']\n",
        "        aug_bboxes = augmented['bboxes']\n",
        "        aug_labels = augmented['class_labels']\n",
        "\n",
        "        # íŒŒì¼ëª… ì„¤ì •\n",
        "        base_name = os.path.splitext(img_file)[0]\n",
        "        aug_img_name = f\"{base_name}_aug{i}.jpg\"\n",
        "        aug_lbl_name = f\"{base_name}_aug{i}.txt\"\n",
        "\n",
        "        # ì´ë¯¸ì§€ ì €ì¥\n",
        "        aug_img_bgr = cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR)\n",
        "        cv2.imwrite(os.path.join(output_img_dir, aug_img_name), aug_img_bgr)\n",
        "\n",
        "        # ë¼ë²¨ ì €ì¥\n",
        "        with open(os.path.join(output_lbl_dir, aug_lbl_name), 'w') as f:\n",
        "            for label, box in zip(aug_labels, aug_bboxes):\n",
        "                f.write(f\"{label} {box[0]:.6f} {box[1]:.6f} {box[2]:.6f} {box[3]:.6f}\\n\")"
      ],
      "metadata": {
        "id": "LwqmruOH0eSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# ì¦ê°•ëœ ì´ë¯¸ì§€ ë° ë¼ë²¨ ê²½ë¡œ\n",
        "aug_img_dir = '/content/augmented/images'\n",
        "aug_lbl_dir = '/content/augmented/labels'\n",
        "\n",
        "# í´ë˜ìŠ¤ ì´ë¦„ ì •ì˜ (YOLO ë¼ë²¨ ì¸ë±ìŠ¤ ê¸°ì¤€)\n",
        "class_names = ['empty', 'occupied']\n",
        "\n",
        "# ì‹œê°í™”í•  ì´ë¯¸ì§€ ìˆ˜\n",
        "NUM_SAMPLES = 5\n",
        "\n",
        "# ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸\n",
        "image_files = [f for f in os.listdir(aug_img_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# ë¬´ì‘ìœ„ ìƒ˜í”Œ ì„ íƒ\n",
        "for img_file in random.sample(image_files, min(NUM_SAMPLES, len(image_files))):\n",
        "    img_path = os.path.join(aug_img_dir, img_file)\n",
        "    label_path = os.path.join(aug_lbl_dir, os.path.splitext(img_file)[0] + '.txt')\n",
        "\n",
        "    image = cv2.imread(img_path)\n",
        "    h, w = image.shape[:2]\n",
        "\n",
        "    if not os.path.exists(label_path):\n",
        "        print(f\"ë¼ë²¨ ì—†ìŒ: {label_path}\")\n",
        "        continue\n",
        "\n",
        "    # ë¼ë²¨ ì½ê¸° ë° ë°”ìš´ë”©ë°•ìŠ¤ ì‹œê°í™”\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            cls, x, y, bw, bh = map(float, line.strip().split())\n",
        "            x1 = int((x - bw / 2) * w)\n",
        "            y1 = int((y - bh / 2) * h)\n",
        "            x2 = int((x + bw / 2) * w)\n",
        "            y2 = int((y + bh / 2) * h)\n",
        "            color = (0, 255, 0) if int(cls) == 0 else (0, 0, 255)\n",
        "            label = class_names[int(cls)]\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "    print(f\"ì‹œê°í™”: {img_file}\")\n",
        "    cv2_imshow(image)"
      ],
      "metadata": {
        "id": "ghrEeYnG0iUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# ì†ŒìŠ¤ ë””ë ‰í† ë¦¬ ëª©ë¡\n",
        "image_sources = [\n",
        "    '/content/Beyond.v3i.yolov8/images/train',\n",
        "    '/content/augmented/images'\n",
        "]\n",
        "\n",
        "label_sources = [\n",
        "    '/content/Beyond.v3i.yolov8/labels/train',\n",
        "    '/content/augmented/labels'\n",
        "]\n",
        "\n",
        "# ëŒ€ìƒ ë””ë ‰í† ë¦¬\n",
        "merged_image_dir = '/content/merged/images'\n",
        "merged_label_dir = '/content/merged/labels'\n",
        "\n",
        "# í™•ì¥ì ì„¤ì •\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "label_extension = '.txt'\n",
        "\n",
        "# ëŒ€ìƒ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "os.makedirs(merged_image_dir, exist_ok=True)\n",
        "os.makedirs(merged_label_dir, exist_ok=True)\n",
        "\n",
        "# ì´ë¯¸ì§€ + ë¼ë²¨ ë³‘í•©\n",
        "for img_src, lbl_src in zip(image_sources, label_sources):\n",
        "    for filename in os.listdir(img_src):\n",
        "        if os.path.splitext(filename)[1].lower() in image_extensions:\n",
        "            base_name, ext = os.path.splitext(filename)\n",
        "\n",
        "            src_img_path = os.path.join(img_src, filename)\n",
        "            src_lbl_path = os.path.join(lbl_src, f\"{base_name}{label_extension}\")\n",
        "\n",
        "            dst_img_path = os.path.join(merged_image_dir, filename)\n",
        "            dst_lbl_path = os.path.join(merged_label_dir, f\"{base_name}{label_extension}\")\n",
        "\n",
        "            # ì´ë¦„ ì¤‘ë³µ ë°©ì§€\n",
        "            counter = 1\n",
        "            while os.path.exists(dst_img_path) or os.path.exists(dst_lbl_path):\n",
        "                new_base = f\"{base_name}_{counter}\"\n",
        "                dst_img_path = os.path.join(merged_image_dir, f\"{new_base}{ext}\")\n",
        "                dst_lbl_path = os.path.join(merged_label_dir, f\"{new_base}{label_extension}\")\n",
        "                counter += 1\n",
        "\n",
        "            shutil.copy2(src_img_path, dst_img_path)\n",
        "\n",
        "            if os.path.exists(src_lbl_path):\n",
        "                shutil.copy2(src_lbl_path, dst_lbl_path)\n",
        "\n",
        "print(\"ëª¨ë“  ì´ë¯¸ì§€ì™€ ë¼ë²¨ì´ /content/merged ë””ë ‰í† ë¦¬ë¡œ ë³‘í•© ì™„ë£Œë¨\")"
      ],
      "metadata": {
        "id": "rcHL5rHS0lYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# ê²½ë¡œ ì„¤ì •\n",
        "image_dir = '/content/merged/images'\n",
        "label_dir = '/content/merged/labels'\n",
        "\n",
        "# í™•ì¥ì ì„¤ì •\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "label_extension = '.txt'\n",
        "\n",
        "# ì´ë¯¸ì§€ ê°œìˆ˜ ì„¸ê¸°\n",
        "image_count = len([\n",
        "    f for f in os.listdir(image_dir)\n",
        "    if os.path.splitext(f)[1].lower() in image_extensions\n",
        "])\n",
        "\n",
        "# ë¼ë²¨ ê°œìˆ˜ ì„¸ê¸°\n",
        "label_count = len([\n",
        "    f for f in os.listdir(label_dir)\n",
        "    if f.endswith(label_extension)\n",
        "])\n",
        "\n",
        "print(f\"ì´ë¯¸ì§€ ìˆ˜: {image_count}ì¥\")\n",
        "print(f\"ë¼ë²¨ ìˆ˜: {label_count}ê°œ\")"
      ],
      "metadata": {
        "id": "nCvGG0GQ0m1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "class_names = ['empty', 'occupied']\n",
        "\n",
        "data = {\n",
        "    'train': '/content/merged/images',\n",
        "    'val': '/content/Beyond.v3i.yolov8/images/val',\n",
        "    'test': '/content/Beyond.v3i.yolov8/images/val',\n",
        "    'names': {i: name for i, name in enumerate(class_names)},\n",
        "    'nc': len(class_names)\n",
        "}\n",
        "\n",
        "yaml_path = '/content/merged/dataset.yaml'\n",
        "\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(data, f, default_flow_style=False)\n",
        "\n",
        "print(f\"dataset.yaml íŒŒì¼ ìƒì„± ì™„ë£Œ: {yaml_path}\")\n"
      ],
      "metadata": {
        "id": "05aa2cc70o2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. YOLOv8 ì„¤ì¹˜ ë° ëª¨ë¸ ë¡œë“œ"
      ],
      "metadata": {
        "id": "AQu8XpHbjA8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ultralytics ì„¤ì¹˜\n",
        "!pip install ultralytics\n",
        "\n",
        "# ëª¨ë¸ ë¡œë“œ\n",
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov8n.pt\")  # ê²½ëŸ‰ ëª¨ë¸ (ë˜ëŠ” yolov8s.pt ë“± ê°€ëŠ¥)\n"
      ],
      "metadata": {
        "id": "f_vXk2l2jDak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### êµ¬ê¸€ ì½”ë© í…ŒìŠ¤íŠ¸ìš©"
      ],
      "metadata": {
        "id": "YG6TVka2GF-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ í•™ìŠµ ì‹œì‘\n",
        "model.train(\n",
        "    data=yaml_path,        # data.yaml ê²½ë¡œ\n",
        "    epochs=10,\n",
        "    imgsz=416,\n",
        "    batch=1,\n",
        "    amp=True,\n",
        "    cache=False,\n",
        "    name=\"yolov8_chair\"\n",
        ")"
      ],
      "metadata": {
        "id": "HbCf0tIbFPlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# ì´ë¯¸ì§€ í´ë” ê²½ë¡œ\n",
        "image_folder = \"/content/Beyond.v31.yolov8/merged/images\"\n",
        "\n",
        "# ì´ë¯¸ì§€ í™•ì¥ì í™•ì¸\n",
        "image_files = glob.glob(image_folder + \"/*.jpg\") + glob.glob(image_folder + \"/*.png\")\n",
        "\n",
        "print(f\"ì´ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì´ ìˆìŠµë‹ˆë‹¤.\")\n",
        "for f in image_files[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥\n",
        "    print(f)"
      ],
      "metadata": {
        "id": "1KZjH0kHFd8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "model = YOLO('/content/runs/detect/yolov8_chair/weights/best.pt')  # ê²½ë¡œ í™•ì¸ í•„ìš”\n",
        "\n",
        "# 2. ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "image_path = ''\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# 3. ì˜ˆì¸¡ ì‹¤í–‰\n",
        "results = model(image, conf=0.1)  # conf ë‚®ì¶°ë³´ê¸°\n",
        "\n",
        "# 4. ê²°ê³¼ ì´ë¯¸ì§€ ì‹œê°í™”\n",
        "res_plotted = results[0].plot()  # ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ (numpy ë°°ì—´)\n",
        "\n",
        "# 5. ì´ë¯¸ì§€ ì¶œë ¥\n",
        "plt.imshow(res_plotted)\n",
        "plt.axis('off')\n",
        "plt.title(\"YOLOv8 Chair Detection Result\")\n",
        "plt.show()\n",
        "\n",
        "# 6. ê²°ê³¼ ì¶œë ¥ (ë°•ìŠ¤ê°€ ì‹¤ì œë¡œ ìˆëŠ”ì§€ í™•ì¸)\n",
        "print(\"íƒì§€ëœ ë°•ìŠ¤ ìˆ˜:\", len(results[0].boxes))\n",
        "print(\"ë°•ìŠ¤ ì •ë³´:\", results[0].boxes.xyxy)\n",
        "print(\"í´ë˜ìŠ¤ ì •ë³´:\", results[0].boxes.cls)\n",
        "print(\"ì‹ ë¢°ë„:\", results[0].boxes.conf)"
      ],
      "metadata": {
        "id": "DWt0r1YCFhO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ˆì¸¡ëœ ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ì¶œë ¥\n",
        "for box in results[0].boxes:\n",
        "    cls = int(box.cls[0])\n",
        "    conf = float(box.conf[0])\n",
        "    xyxy = box.xyxy[0].tolist()\n",
        "    print(f\"Class: {model.names[cls]}, Conf: {conf:.2f}, BBox: {xyxy}\")"
      ],
      "metadata": {
        "id": "KsXssaY2Fdrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# ê²½ë¡œ: YOLO í•™ìŠµ ê²°ê³¼ ë””ë ‰í† ë¦¬\n",
        "results_csv_path = \"/content/runs/detect/train2/results.csv\"\n",
        "\n",
        "# CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "assert os.path.exists(results_csv_path), f\"CSV íŒŒì¼ ì—†ìŒ: {results_csv_path}\"\n",
        "df = pd.read_csv(results_csv_path)\n",
        "\n",
        "# ê¸°ë³¸ ì •ë³´\n",
        "epochs = df.index + 1  # 0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ +1\n",
        "\n",
        "# âœ… ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# ---- Accuracy / Precision / Recall ----\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, df[\"metrics/precision(B)\"], label=\"Precision\", marker='o')\n",
        "plt.plot(epochs, df[\"metrics/recall(B)\"], label=\"Recall\", marker='o')\n",
        "plt.plot(epochs, df[\"metrics/mAP50(B)\"], label=\"mAP50\", marker='o')\n",
        "plt.title(\"Precision / Recall / mAP\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# ---- Loss ----\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, df[\"train/box_loss\"], label=\"Box Loss\", marker='x')\n",
        "plt.plot(epochs, df[\"train/cls_loss\"], label=\"Class Loss\", marker='x')\n",
        "plt.plot(epochs, df[\"val/box_loss\"], label=\"Val Box Loss\", linestyle=\"--\")\n",
        "plt.plot(epochs, df[\"val/cls_loss\"], label=\"Val Class Loss\", linestyle=\"--\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Mx0WpFyFj_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ê²€ì¶œ ì‹¤í–‰ (validation ì´ë¯¸ì§€ ëŒ€ìƒ)\n",
        "val_images_path = '/content/Beyond.v3i.yolov8/images/val'\n",
        "\n",
        "results = model.predict(\n",
        "    source=val_images_path,\n",
        "    conf=0.3,\n",
        "    save=True\n",
        ")\n",
        "\n",
        "# ì‹œê°í™” ê²°ê³¼ ë³´ê¸°\n",
        "results[0].show()"
      ],
      "metadata": {
        "id": "0AKkuVm1FoEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# YOLO val ê²°ê³¼ ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "val_result_dir = \"/content/runs/detect/val\"\n",
        "\n",
        "# íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "img_files = [f for f in os.listdir(val_result_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# ë¬´ì‘ìœ„ 5ì¥ ì„ íƒ\n",
        "sample_imgs = random.sample(img_files, min(5, len(img_files)))\n",
        "\n",
        "# ì‹œê°í™”\n",
        "for f in sample_imgs:\n",
        "    img_path = os.path.join(val_result_dir, f)\n",
        "    img = cv2.imread(img_path)\n",
        "    print(f\"{f}\")\n",
        "    cv2_imshow(img)"
      ],
      "metadata": {
        "id": "dXCdSEyUFrhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. í•™ìŠµ ì‹¤í–‰ (960x960)"
      ],
      "metadata": {
        "id": "T1h60Xr0jE_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ í•™ìŠµ ì‹œì‘\n",
        "model.train(\n",
        "    data=yaml_path,        # data.yaml ê²½ë¡œ\n",
        "    epochs=50,\n",
        "    imgsz=960,\n",
        "    batch=4,\n",
        "    name=\"yolov8_chair\"\n",
        ")"
      ],
      "metadata": {
        "id": "GYop-AuJjH2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val()\n",
        "\n",
        "# ì£¼ìš” ì§€í‘œ ì¶œë ¥\n",
        "print(f\"mAP@0.5:       {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95:   {metrics.box.map:.4f}\")\n",
        "print(f\"Precision:      {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall:         {metrics.box.mr:.4f}\")"
      ],
      "metadata": {
        "id": "C55WMyXnHmKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. í•™ìŠµëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡ í™•ì¸ (960x960)"
      ],
      "metadata": {
        "id": "uRJmh548jKbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# ì´ë¯¸ì§€ í´ë” ê²½ë¡œ\n",
        "image_folder = \"/content/Beyond.v31.yolov8/merged/images\"\n",
        "\n",
        "# ì´ë¯¸ì§€ í™•ì¥ì í™•ì¸\n",
        "image_files = glob.glob(image_folder + \"/*.jpg\") + glob.glob(image_folder + \"/*.png\")\n",
        "\n",
        "print(f\"ì´ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì´ ìˆìŠµë‹ˆë‹¤.\")\n",
        "for f in image_files[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥\n",
        "    print(f)"
      ],
      "metadata": {
        "id": "meWwzf7YjMfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "model = YOLO('/content/runs/detect/yolov8_chair/weights/best.pt')  # ê²½ë¡œ í™•ì¸ í•„ìš”\n",
        "\n",
        "# 2. ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "image_path = ''\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# 3. ì˜ˆì¸¡ ì‹¤í–‰\n",
        "results = model(image, conf=0.1)  # conf ë‚®ì¶°ë³´ê¸°\n",
        "\n",
        "# 4. ê²°ê³¼ ì´ë¯¸ì§€ ì‹œê°í™”\n",
        "res_plotted = results[0].plot()  # ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ (numpy ë°°ì—´)\n",
        "\n",
        "# 5. ì´ë¯¸ì§€ ì¶œë ¥\n",
        "plt.imshow(res_plotted)\n",
        "plt.axis('off')\n",
        "plt.title(\"YOLOv8 Chair Detection Result\")\n",
        "plt.show()\n",
        "\n",
        "# 6. ê²°ê³¼ ì¶œë ¥ (ë°•ìŠ¤ê°€ ì‹¤ì œë¡œ ìˆëŠ”ì§€ í™•ì¸)\n",
        "print(\"íƒì§€ëœ ë°•ìŠ¤ ìˆ˜:\", len(results[0].boxes))\n",
        "print(\"ë°•ìŠ¤ ì •ë³´:\", results[0].boxes.xyxy)\n",
        "print(\"í´ë˜ìŠ¤ ì •ë³´:\", results[0].boxes.cls)\n",
        "print(\"ì‹ ë¢°ë„:\", results[0].boxes.conf)"
      ],
      "metadata": {
        "id": "S1727UjP0k9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.names)"
      ],
      "metadata": {
        "id": "VBjkIzwmjS0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ˆì¸¡ëœ ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ì¶œë ¥\n",
        "for box in results[0].boxes:\n",
        "    cls = int(box.cls[0])\n",
        "    conf = float(box.conf[0])\n",
        "    xyxy = box.xyxy[0].tolist()\n",
        "    print(f\"Class: {model.names[cls]}, Conf: {conf:.2f}, BBox: {xyxy}\")"
      ],
      "metadata": {
        "id": "7SblHy8bjVWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# ê²½ë¡œ: YOLO í•™ìŠµ ê²°ê³¼ ë””ë ‰í† ë¦¬\n",
        "results_csv_path = \"/content/runs/detect/train2/results.csv\"\n",
        "\n",
        "# CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "assert os.path.exists(results_csv_path), f\"CSV íŒŒì¼ ì—†ìŒ: {results_csv_path}\"\n",
        "df = pd.read_csv(results_csv_path)\n",
        "\n",
        "# ê¸°ë³¸ ì •ë³´\n",
        "epochs = df.index + 1  # 0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ +1\n",
        "\n",
        "# âœ… ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# ---- Accuracy / Precision / Recall ----\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, df[\"metrics/precision(B)\"], label=\"Precision\", marker='o')\n",
        "plt.plot(epochs, df[\"metrics/recall(B)\"], label=\"Recall\", marker='o')\n",
        "plt.plot(epochs, df[\"metrics/mAP50(B)\"], label=\"mAP50\", marker='o')\n",
        "plt.title(\"Precision / Recall / mAP\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# ---- Loss ----\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, df[\"train/box_loss\"], label=\"Box Loss\", marker='x')\n",
        "plt.plot(epochs, df[\"train/cls_loss\"], label=\"Class Loss\", marker='x')\n",
        "plt.plot(epochs, df[\"val/box_loss\"], label=\"Val Box Loss\", linestyle=\"--\")\n",
        "plt.plot(epochs, df[\"val/cls_loss\"], label=\"Val Class Loss\", linestyle=\"--\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zHrpbNqj7SmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Valid ì„¸íŠ¸ í…ŒìŠ¤íŠ¸ (960x960)"
      ],
      "metadata": {
        "id": "RivXRJDEjXkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ê²€ì¶œ ì‹¤í–‰ (validation ì´ë¯¸ì§€ ëŒ€ìƒ)\n",
        "val_images_path = '/content/Beyond.v3i.yolov8/images/val'\n",
        "\n",
        "results = model.predict(\n",
        "    source=val_images_path,\n",
        "    conf=0.3,\n",
        "    save=True\n",
        ")\n",
        "\n",
        "# ì‹œê°í™” ê²°ê³¼ ë³´ê¸°\n",
        "results[0].show()\n"
      ],
      "metadata": {
        "id": "0fuHuXmKjXTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# YOLO val ê²°ê³¼ ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "val_result_dir = \"/content/runs/detect/val\"\n",
        "\n",
        "# íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "img_files = [f for f in os.listdir(val_result_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# ë¬´ì‘ìœ„ 5ì¥ ì„ íƒ\n",
        "sample_imgs = random.sample(img_files, min(5, len(img_files)))\n",
        "\n",
        "# ì‹œê°í™”\n",
        "for f in sample_imgs:\n",
        "    img_path = os.path.join(val_result_dir, f)\n",
        "    img = cv2.imread(img_path)\n",
        "    print(f\"{f}\")\n",
        "    cv2_imshow(img)"
      ],
      "metadata": {
        "id": "6CQfTPKa7h8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. í•™ìŠµ ì‹¤í–‰ (640x640)"
      ],
      "metadata": {
        "id": "6OqwVsQU2bWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ í•™ìŠµ ì‹œì‘\n",
        "model.train(\n",
        "    data=yaml_path,        # data.yaml ê²½ë¡œ\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=1,\n",
        "    amp=True,\n",
        "    name=\"yolov8_chair\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEtTtzM-2ac8",
        "outputId": "880ba045-febe-4692-b8c0-c8f4921db46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.172 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=False, augment=False, auto_augment=randaugment, batch=1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/merged/dataset.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8_chair, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/yolov8_chair, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 23.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 46.3Â±24.6 MB/s, size: 97.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/merged/labels... 558 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 558/558 [00:01<00:00, 355.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/merged/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 47.1Â±8.0 MB/s, size: 136.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Beyond.v3i.yolov8/labels/val... 47 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 140.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Beyond.v3i.yolov8/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/yolov8_chair/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/yolov8_chair\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/558 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val()\n",
        "\n",
        "# ì£¼ìš” ì§€í‘œ ì¶œë ¥\n",
        "print(f\"mAP@0.5:       {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95:   {metrics.box.map:.4f}\")\n",
        "print(f\"Precision:      {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall:         {metrics.box.mr:.4f}\")"
      ],
      "metadata": {
        "id": "Zv8-iDD72iUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. í•™ìŠµëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡ í™•ì¸ (640x640)"
      ],
      "metadata": {
        "id": "Z81lJFLD2dCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# ì´ë¯¸ì§€ í´ë” ê²½ë¡œ\n",
        "image_folder = \"/content/Beyond.v31.yolov8/merged/images\"\n",
        "\n",
        "# ì´ë¯¸ì§€ í™•ì¥ì í™•ì¸\n",
        "image_files = glob.glob(image_folder + \"/*.jpg\") + glob.glob(image_folder + \"/*.png\")\n",
        "\n",
        "print(f\"ì´ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì´ ìˆìŠµë‹ˆë‹¤.\")\n",
        "for f in image_files[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥\n",
        "    print(f)"
      ],
      "metadata": {
        "id": "JI43Xne72nY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "model = YOLO('/content/runs/detect/yolov8_chair/weights/best.pt')  # ê²½ë¡œ í™•ì¸ í•„ìš”\n",
        "\n",
        "# 2. ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "image_path = ''\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# 3. ì˜ˆì¸¡ ì‹¤í–‰\n",
        "results = model(image, conf=0.1)  # conf ë‚®ì¶°ë³´ê¸°\n",
        "\n",
        "# 4. ê²°ê³¼ ì´ë¯¸ì§€ ì‹œê°í™”\n",
        "res_plotted = results[0].plot()  # ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ (numpy ë°°ì—´)\n",
        "\n",
        "# 5. ì´ë¯¸ì§€ ì¶œë ¥\n",
        "plt.imshow(res_plotted)\n",
        "plt.axis('off')\n",
        "plt.title(\"YOLOv8 Chair Detection Result\")\n",
        "plt.show()\n",
        "\n",
        "# 6. ê²°ê³¼ ì¶œë ¥ (ë°•ìŠ¤ê°€ ì‹¤ì œë¡œ ìˆëŠ”ì§€ í™•ì¸)\n",
        "print(\"íƒì§€ëœ ë°•ìŠ¤ ìˆ˜:\", len(results[0].boxes))\n",
        "print(\"ë°•ìŠ¤ ì •ë³´:\", results[0].boxes.xyxy)\n",
        "print(\"í´ë˜ìŠ¤ ì •ë³´:\", results[0].boxes.cls)\n",
        "print(\"ì‹ ë¢°ë„:\", results[0].boxes.conf)"
      ],
      "metadata": {
        "id": "N_NM76X6221H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ˆì¸¡ëœ ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ì¶œë ¥\n",
        "for box in results[0].boxes:\n",
        "    cls = int(box.cls[0])\n",
        "    conf = float(box.conf[0])\n",
        "    xyxy = box.xyxy[0].tolist()\n",
        "    print(f\"Class: {model.names[cls]}, Conf: {conf:.2f}, BBox: {xyxy}\")"
      ],
      "metadata": {
        "id": "tWv8t-sG3GtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# ê²½ë¡œ: YOLO í•™ìŠµ ê²°ê³¼ ë””ë ‰í† ë¦¬\n",
        "results_csv_path = \"/content/runs/detect/train2/results.csv\"\n",
        "\n",
        "# CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "assert os.path.exists(results_csv_path), f\"CSV íŒŒì¼ ì—†ìŒ: {results_csv_path}\"\n",
        "df = pd.read_csv(results_csv_path)\n",
        "\n",
        "# ê¸°ë³¸ ì •ë³´\n",
        "epochs = df.index + 1  # 0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ +1\n",
        "\n",
        "# âœ… ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# ---- Accuracy / Precision / Recall ----\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, df[\"metrics/precision(B)\"], label=\"Precision\", marker='o')\n",
        "plt.plot(epochs, df[\"metrics/recall(B)\"], label=\"Recall\", marker='o')\n",
        "plt.plot(epochs, df[\"metrics/mAP50(B)\"], label=\"mAP50\", marker='o')\n",
        "plt.title(\"Precision / Recall / mAP\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# ---- Loss ----\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, df[\"train/box_loss\"], label=\"Box Loss\", marker='x')\n",
        "plt.plot(epochs, df[\"train/cls_loss\"], label=\"Class Loss\", marker='x')\n",
        "plt.plot(epochs, df[\"val/box_loss\"], label=\"Val Box Loss\", linestyle=\"--\")\n",
        "plt.plot(epochs, df[\"val/cls_loss\"], label=\"Val Class Loss\", linestyle=\"--\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cwcKY3k07MPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Valid ì„¸íŠ¸ í…ŒìŠ¤íŠ¸ (640x640)"
      ],
      "metadata": {
        "id": "4foRzPe63XbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ê²€ì¶œ ì‹¤í–‰ (validation ì´ë¯¸ì§€ ëŒ€ìƒ)\n",
        "val_images_path = '/content/Beyond.v3i.yolov8/images/val'\n",
        "\n",
        "results = model.predict(\n",
        "    source=val_images_path,\n",
        "    conf=0.3,\n",
        "    save=True\n",
        ")\n",
        "\n",
        "# ì‹œê°í™” ê²°ê³¼ ë³´ê¸°\n",
        "results[0].show()"
      ],
      "metadata": {
        "id": "HOk0lwEM3eZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# YOLO val ê²°ê³¼ ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "val_result_dir = \"/content/runs/detect/val\"\n",
        "\n",
        "# íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "img_files = [f for f in os.listdir(val_result_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# ë¬´ì‘ìœ„ 5ì¥ ì„ íƒ\n",
        "sample_imgs = random.sample(img_files, min(5, len(img_files)))\n",
        "\n",
        "# ì‹œê°í™”\n",
        "for f in sample_imgs:\n",
        "    img_path = os.path.join(val_result_dir, f)\n",
        "    img = cv2.imread(img_path)\n",
        "    print(f\"{f}\")\n",
        "    cv2_imshow(img)"
      ],
      "metadata": {
        "id": "CXnnVMK67e2W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}